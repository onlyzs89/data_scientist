{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'input/stage1_train/'\n",
    "TEST_DIR = 'input/stage1_test/'\n",
    "WIDTH = 128\n",
    "HEIGHT = 128\n",
    "CHANNEL = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ids = os.listdir('input/stage1_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = []\n",
    "Y_train = []\n",
    "for d in train_ids:\n",
    "    base_path = os.path.join(TRAIN_DIR, d)\n",
    "    img = cv2.imread(os.path.join(base_path,\"images\",d+\".png\"))\n",
    "    img = cv2.resize(img,(HEIGHT,WIDTH))/255\n",
    "    X_train.append(img)\n",
    "    \n",
    "    masks_list = os.listdir(os.path.join(base_path,\"masks\"))\n",
    "    masks = []\n",
    "    for m in masks_list:\n",
    "        mask = cv2.imread(os.path.join(base_path,\"masks\",m), cv2.IMREAD_GRAYSCALE)\n",
    "        mask = cv2.resize(mask,(HEIGHT,WIDTH))/255\n",
    "        masks.append(mask)\n",
    "    masks = np.array(masks)\n",
    "    masks = np.amax(masks,axis=0)\n",
    "    masks = np.expand_dims(masks, axis=-1)\n",
    "    Y_train.append(masks)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import rotate as rot\n",
    "def augment(x,y):\n",
    "    x_mirror_lr = []\n",
    "    x_mirror_ud = []\n",
    "    x_rotate = []\n",
    "    x_rotate_2 = []\n",
    "    x_rotate_3 = []\n",
    "    x_rotate_4 = []\n",
    "    y_mirror_lr = []\n",
    "    y_mirror_ud = []\n",
    "    y_rotate = []\n",
    "    y_rotate_2 = []\n",
    "    y_rotate_3 = []\n",
    "    y_rotate_4 = []\n",
    "    for i in range(0,x.shape[0]):\n",
    "        band_1 = x[i,:,:,0]\n",
    "        band_2 = x[i,:,:,1]\n",
    "        band_3 = x[i,:,:,2]\n",
    "        band_y = y[i,:,:,0]\n",
    "            \n",
    "        # mirror left-right\n",
    "        band_1_mirror_lr = np.flip(band_1, 0)\n",
    "        band_2_mirror_lr = np.flip(band_2, 0)\n",
    "        band_3_mirror_lr = np.flip(band_3, 0)\n",
    "        x_mirror_lr.append(np.dstack((band_1_mirror_lr, band_2_mirror_lr, band_3_mirror_lr)))\n",
    "        y_mirror_lr.append(np.expand_dims(np.flip(band_y, 0), axis=-1))\n",
    "        \n",
    "        # mirror up-down\n",
    "        band_1_mirror_ud = np.flip(band_1, 1)\n",
    "        band_2_mirror_ud = np.flip(band_2, 1)\n",
    "        band_3_mirror_ud = np.flip(band_3, 1)\n",
    "        x_mirror_ud.append(np.dstack((band_1_mirror_ud, band_2_mirror_ud, band_3_mirror_ud)))\n",
    "        y_mirror_ud.append(np.expand_dims(np.flip(band_y, 1), axis=-1))\n",
    "        \n",
    "        #rotate \n",
    "        band_1_rotate = rot(band_1, 45, reshape=False)\n",
    "        band_2_rotate = rot(band_2, 45, reshape=False)\n",
    "        band_3_rotate = rot(band_3, 45, reshape=False)\n",
    "        x_rotate.append(np.dstack((band_1_rotate, band_2_rotate, band_3_rotate)))\n",
    "        y_rotate.append(np.expand_dims(rot(band_y, 45, reshape=False), axis=-1))\n",
    "        \n",
    "        #rotate2 \n",
    "        band_1_rotate_2 = rot(band_1, -45, reshape=False)\n",
    "        band_2_rotate_2 = rot(band_2, -45, reshape=False)\n",
    "        band_3_rotate_2 = rot(band_3, -45, reshape=False)\n",
    "        x_rotate_2.append(np.dstack((band_1_rotate_2, band_2_rotate_2, band_3_rotate_2)))\n",
    "        y_rotate_2.append(np.expand_dims(rot(band_y, -45, reshape=False), axis=-1))\n",
    "        \n",
    "        #rotate3 \n",
    "        band_1_rotate_3 = rot(band_1, 135, reshape=False)\n",
    "        band_2_rotate_3 = rot(band_2, 135, reshape=False)\n",
    "        band_3_rotate_3 = rot(band_3, 135, reshape=False)\n",
    "        x_rotate_3.append(np.dstack((band_1_rotate_3, band_2_rotate_3, band_3_rotate_3)))\n",
    "        y_rotate_3.append(np.expand_dims(rot(band_y, 135, reshape=False), axis=-1))\n",
    "        \n",
    "        #rotate4 \n",
    "        band_1_rotate_4 = rot(band_1, -135, reshape=False)\n",
    "        band_2_rotate_4 = rot(band_2, -135, reshape=False)\n",
    "        band_3_rotate_4 = rot(band_3, -135, reshape=False)\n",
    "        x_rotate_4.append(np.dstack((band_1_rotate_4, band_2_rotate_4, band_3_rotate_4)))\n",
    "        y_rotate_4.append(np.expand_dims(rot(band_y, -135, reshape=False), axis=-1))\n",
    "        \n",
    "    x = np.concatenate((x, np.array(x_mirror_lr), np.array(x_mirror_ud), np.array(x_rotate), np.array(x_rotate_2), np.array(x_rotate_3), np.array(x_rotate_4)))\n",
    "    y = np.concatenate((y, np.array(y_mirror_lr), np.array(y_mirror_ud), np.array(y_rotate), np.array(y_rotate_2), np.array(y_rotate_3), np.array(y_rotate_4)))\n",
    "    \n",
    "    del x_mirror_lr,x_mirror_ud,x_rotate,x_rotate_2,x_rotate_3,x_rotate_4\n",
    "    del y_mirror_lr,y_mirror_ud,y_rotate,y_rotate_2,y_rotate_3,y_rotate_4\n",
    "    \n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4690, 128, 128, 3), (4690, 128, 128, 1))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,Y_train = augment(X_train,Y_train)\n",
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    inputs = Input((HEIGHT, WIDTH, CHANNEL))\n",
    "    c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (inputs)\n",
    "    c1 = Dropout(0.1) (c1)\n",
    "    c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\n",
    "    p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "    c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\n",
    "    c2 = Dropout(0.1) (c2)\n",
    "    c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\n",
    "    p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "    c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\n",
    "    c3 = Dropout(0.2) (c3)\n",
    "    c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n",
    "    p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "    c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\n",
    "    c4 = Dropout(0.2) (c4)\n",
    "    c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "    c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\n",
    "    c5 = Dropout(0.3) (c5)\n",
    "    c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n",
    "\n",
    "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\n",
    "    c6 = Dropout(0.2) (c6)\n",
    "    c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n",
    "\n",
    "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\n",
    "    c7 = Dropout(0.2) (c7)\n",
    "    c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n",
    "\n",
    "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\n",
    "    c8 = Dropout(0.1) (c8)\n",
    "    c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n",
    "\n",
    "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\n",
    "    c9 = Dropout(0.1) (c9)\n",
    "    c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "    \n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[mean_iou])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4221 samples, validate on 469 samples\n",
      "Epoch 1/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.1970 - mean_iou: 0.5217Epoch 00001: val_loss improved from inf to 0.12596, saving model to model_02.h5\n",
      "4221/4221 [==============================] - 121s 29ms/step - loss: 0.1969 - mean_iou: 0.5220 - val_loss: 0.1260 - val_mean_iou: 0.5804\n",
      "Epoch 2/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.1220 - mean_iou: 0.6131Epoch 00002: val_loss improved from 0.12596 to 0.09749, saving model to model_02.h5\n",
      "4221/4221 [==============================] - 121s 29ms/step - loss: 0.1220 - mean_iou: 0.6132 - val_loss: 0.0975 - val_mean_iou: 0.6391\n",
      "Epoch 3/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.0970 - mean_iou: 0.6567Epoch 00003: val_loss improved from 0.09749 to 0.08484, saving model to model_02.h5\n",
      "4221/4221 [==============================] - 121s 29ms/step - loss: 0.0970 - mean_iou: 0.6568 - val_loss: 0.0848 - val_mean_iou: 0.6713\n",
      "Epoch 4/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.0853 - mean_iou: 0.6818Epoch 00004: val_loss improved from 0.08484 to 0.07413, saving model to model_02.h5\n",
      "4221/4221 [==============================] - 121s 29ms/step - loss: 0.0852 - mean_iou: 0.6818 - val_loss: 0.0741 - val_mean_iou: 0.6909\n",
      "Epoch 5/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.0800 - mean_iou: 0.6978Epoch 00005: val_loss improved from 0.07413 to 0.06734, saving model to model_02.h5\n",
      "4221/4221 [==============================] - 121s 29ms/step - loss: 0.0801 - mean_iou: 0.6978 - val_loss: 0.0673 - val_mean_iou: 0.7041\n",
      "Epoch 6/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.0756 - mean_iou: 0.7090Epoch 00006: val_loss improved from 0.06734 to 0.06477, saving model to model_02.h5\n",
      "4221/4221 [==============================] - 121s 29ms/step - loss: 0.0756 - mean_iou: 0.7090 - val_loss: 0.0648 - val_mean_iou: 0.7134\n",
      "Epoch 7/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.0723 - mean_iou: 0.7170Epoch 00007: val_loss improved from 0.06477 to 0.06262, saving model to model_02.h5\n",
      "4221/4221 [==============================] - 121s 29ms/step - loss: 0.0722 - mean_iou: 0.7171 - val_loss: 0.0626 - val_mean_iou: 0.7206\n",
      "Epoch 8/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.0692 - mean_iou: 0.7235Epoch 00008: val_loss improved from 0.06262 to 0.06108, saving model to model_02.h5\n",
      "4221/4221 [==============================] - 121s 29ms/step - loss: 0.0692 - mean_iou: 0.7235 - val_loss: 0.0611 - val_mean_iou: 0.7262\n",
      "Epoch 9/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.0678 - mean_iou: 0.7287Epoch 00009: val_loss did not improve\n",
      "4221/4221 [==============================] - 121s 29ms/step - loss: 0.0678 - mean_iou: 0.7287 - val_loss: 0.0615 - val_mean_iou: 0.7308\n",
      "Epoch 10/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.0668 - mean_iou: 0.7328Epoch 00010: val_loss improved from 0.06108 to 0.05982, saving model to model_02.h5\n",
      "4221/4221 [==============================] - 121s 29ms/step - loss: 0.0669 - mean_iou: 0.7328 - val_loss: 0.0598 - val_mean_iou: 0.7345\n",
      "Epoch 11/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.0651 - mean_iou: 0.7360Epoch 00011: val_loss improved from 0.05982 to 0.05883, saving model to model_02.h5\n",
      "4221/4221 [==============================] - 121s 29ms/step - loss: 0.0650 - mean_iou: 0.7361 - val_loss: 0.0588 - val_mean_iou: 0.7377\n",
      "Epoch 12/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.0640 - mean_iou: 0.7391Epoch 00012: val_loss did not improve\n",
      "4221/4221 [==============================] - 121s 29ms/step - loss: 0.0641 - mean_iou: 0.7391 - val_loss: 0.0593 - val_mean_iou: 0.7405\n",
      "Epoch 13/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.0640 - mean_iou: 0.7416Epoch 00013: val_loss improved from 0.05883 to 0.05717, saving model to model_02.h5\n",
      "4221/4221 [==============================] - 121s 29ms/step - loss: 0.0641 - mean_iou: 0.7416 - val_loss: 0.0572 - val_mean_iou: 0.7428\n",
      "Epoch 14/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.0622 - mean_iou: 0.7440Epoch 00014: val_loss improved from 0.05717 to 0.05662, saving model to model_02.h5\n",
      "4221/4221 [==============================] - 121s 29ms/step - loss: 0.0621 - mean_iou: 0.7440 - val_loss: 0.0566 - val_mean_iou: 0.7450\n",
      "Epoch 15/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.0625 - mean_iou: 0.7460Epoch 00015: val_loss improved from 0.05662 to 0.05555, saving model to model_02.h5\n",
      "4221/4221 [==============================] - 121s 29ms/step - loss: 0.0625 - mean_iou: 0.7460 - val_loss: 0.0556 - val_mean_iou: 0.7468\n",
      "Epoch 16/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.0617 - mean_iou: 0.7477Epoch 00016: val_loss improved from 0.05555 to 0.05487, saving model to model_02.h5\n",
      "4221/4221 [==============================] - 121s 29ms/step - loss: 0.0617 - mean_iou: 0.7477 - val_loss: 0.0549 - val_mean_iou: 0.7485\n",
      "Epoch 17/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.0607 - mean_iou: 0.7493Epoch 00017: val_loss improved from 0.05487 to 0.05471, saving model to model_02.h5\n",
      "4221/4221 [==============================] - 121s 29ms/step - loss: 0.0607 - mean_iou: 0.7493 - val_loss: 0.0547 - val_mean_iou: 0.7501\n",
      "Epoch 18/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.0604 - mean_iou: 0.7508Epoch 00018: val_loss did not improve\n",
      "4221/4221 [==============================] - 121s 29ms/step - loss: 0.0603 - mean_iou: 0.7508 - val_loss: 0.0549 - val_mean_iou: 0.7515\n",
      "Epoch 19/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.0618 - mean_iou: 0.7521Epoch 00019: val_loss did not improve\n",
      "4221/4221 [==============================] - 121s 29ms/step - loss: 0.0619 - mean_iou: 0.7521 - val_loss: 0.0566 - val_mean_iou: 0.7527\n",
      "Epoch 20/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.0604 - mean_iou: 0.7532Epoch 00020: val_loss improved from 0.05471 to 0.05303, saving model to model_02.h5\n",
      "4221/4221 [==============================] - 121s 29ms/step - loss: 0.0603 - mean_iou: 0.7532 - val_loss: 0.0530 - val_mean_iou: 0.7538\n",
      "Epoch 21/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.0590 - mean_iou: 0.7543Epoch 00021: val_loss did not improve\n",
      "4221/4221 [==============================] - 121s 29ms/step - loss: 0.0590 - mean_iou: 0.7543 - val_loss: 0.0536 - val_mean_iou: 0.7549\n",
      "Epoch 22/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.0583 - mean_iou: 0.7554Epoch 00022: val_loss improved from 0.05303 to 0.05186, saving model to model_02.h5\n",
      "4221/4221 [==============================] - 121s 29ms/step - loss: 0.0584 - mean_iou: 0.7554 - val_loss: 0.0519 - val_mean_iou: 0.7560\n",
      "Epoch 23/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.0576 - mean_iou: 0.7565Epoch 00023: val_loss did not improve\n",
      "4221/4221 [==============================] - 121s 29ms/step - loss: 0.0577 - mean_iou: 0.7565 - val_loss: 0.0520 - val_mean_iou: 0.7570\n",
      "Epoch 24/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.0583 - mean_iou: 0.7574Epoch 00024: val_loss did not improve\n",
      "4221/4221 [==============================] - 121s 29ms/step - loss: 0.0582 - mean_iou: 0.7574 - val_loss: 0.0522 - val_mean_iou: 0.7579\n",
      "Epoch 25/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.0583 - mean_iou: 0.7583Epoch 00025: val_loss did not improve\n",
      "4221/4221 [==============================] - 121s 29ms/step - loss: 0.0584 - mean_iou: 0.7583 - val_loss: 0.0523 - val_mean_iou: 0.7587\n",
      "Epoch 26/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.0579 - mean_iou: 0.7591Epoch 00026: val_loss improved from 0.05186 to 0.05122, saving model to model_02.h5\n",
      "4221/4221 [==============================] - 121s 29ms/step - loss: 0.0579 - mean_iou: 0.7591 - val_loss: 0.0512 - val_mean_iou: 0.7595\n",
      "Epoch 27/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.0568 - mean_iou: 0.7598Epoch 00027: val_loss improved from 0.05122 to 0.05093, saving model to model_02.h5\n",
      "4221/4221 [==============================] - 121s 29ms/step - loss: 0.0568 - mean_iou: 0.7598 - val_loss: 0.0509 - val_mean_iou: 0.7602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.0568 - mean_iou: 0.7606Epoch 00028: val_loss did not improve\n",
      "4221/4221 [==============================] - 121s 29ms/step - loss: 0.0567 - mean_iou: 0.7606 - val_loss: 0.0512 - val_mean_iou: 0.7610\n",
      "Epoch 29/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.0562 - mean_iou: 0.7614Epoch 00029: val_loss did not improve\n",
      "4221/4221 [==============================] - 120s 29ms/step - loss: 0.0562 - mean_iou: 0.7614 - val_loss: 0.0513 - val_mean_iou: 0.7617\n",
      "Epoch 30/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.0560 - mean_iou: 0.7620Epoch 00030: val_loss improved from 0.05093 to 0.05073, saving model to model_02.h5\n",
      "4221/4221 [==============================] - 121s 29ms/step - loss: 0.0561 - mean_iou: 0.7620 - val_loss: 0.0507 - val_mean_iou: 0.7623\n",
      "Epoch 31/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.0561 - mean_iou: 0.7626Epoch 00031: val_loss did not improve\n",
      "4221/4221 [==============================] - 121s 29ms/step - loss: 0.0561 - mean_iou: 0.7626 - val_loss: 0.0536 - val_mean_iou: 0.7629\n",
      "Epoch 32/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.0575 - mean_iou: 0.7632Epoch 00032: val_loss improved from 0.05073 to 0.04987, saving model to model_02.h5\n",
      "4221/4221 [==============================] - 121s 29ms/step - loss: 0.0574 - mean_iou: 0.7632 - val_loss: 0.0499 - val_mean_iou: 0.7635\n",
      "Epoch 33/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.0561 - mean_iou: 0.7637Epoch 00033: val_loss did not improve\n",
      "4221/4221 [==============================] - 121s 29ms/step - loss: 0.0560 - mean_iou: 0.7637 - val_loss: 0.0508 - val_mean_iou: 0.7640\n",
      "Epoch 34/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.0558 - mean_iou: 0.7643Epoch 00034: val_loss did not improve\n",
      "4221/4221 [==============================] - 121s 29ms/step - loss: 0.0558 - mean_iou: 0.7643 - val_loss: 0.0501 - val_mean_iou: 0.7645\n",
      "Epoch 35/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.0552 - mean_iou: 0.7648Epoch 00035: val_loss did not improve\n",
      "4221/4221 [==============================] - 121s 29ms/step - loss: 0.0554 - mean_iou: 0.7648 - val_loss: 0.0507 - val_mean_iou: 0.7650\n",
      "Epoch 36/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.0554 - mean_iou: 0.7653Epoch 00036: val_loss did not improve\n",
      "4221/4221 [==============================] - 121s 29ms/step - loss: 0.0555 - mean_iou: 0.7653 - val_loss: 0.0506 - val_mean_iou: 0.7655\n",
      "Epoch 37/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.0547 - mean_iou: 0.7657Epoch 00037: val_loss improved from 0.04987 to 0.04925, saving model to model_02.h5\n",
      "4221/4221 [==============================] - 121s 29ms/step - loss: 0.0547 - mean_iou: 0.7657 - val_loss: 0.0492 - val_mean_iou: 0.7660\n",
      "Epoch 38/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.0550 - mean_iou: 0.7662Epoch 00038: val_loss did not improve\n",
      "4221/4221 [==============================] - 121s 29ms/step - loss: 0.0550 - mean_iou: 0.7662 - val_loss: 0.0492 - val_mean_iou: 0.7664\n",
      "Epoch 39/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.0543 - mean_iou: 0.7666Epoch 00039: val_loss did not improve\n",
      "4221/4221 [==============================] - 121s 29ms/step - loss: 0.0543 - mean_iou: 0.7666 - val_loss: 0.0499 - val_mean_iou: 0.7669\n",
      "Epoch 40/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.0552 - mean_iou: 0.7670Epoch 00040: val_loss did not improve\n",
      "4221/4221 [==============================] - 121s 29ms/step - loss: 0.0552 - mean_iou: 0.7670 - val_loss: 0.0502 - val_mean_iou: 0.7673\n",
      "Epoch 41/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.0546 - mean_iou: 0.7674Epoch 00041: val_loss improved from 0.04925 to 0.04898, saving model to model_02.h5\n",
      "4221/4221 [==============================] - 121s 29ms/step - loss: 0.0548 - mean_iou: 0.7674 - val_loss: 0.0490 - val_mean_iou: 0.7676\n",
      "Epoch 42/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.0536 - mean_iou: 0.7679Epoch 00042: val_loss did not improve\n",
      "4221/4221 [==============================] - 121s 29ms/step - loss: 0.0536 - mean_iou: 0.7679 - val_loss: 0.0497 - val_mean_iou: 0.7681\n",
      "Epoch 43/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.0540 - mean_iou: 0.7682Epoch 00043: val_loss improved from 0.04898 to 0.04869, saving model to model_02.h5\n",
      "4221/4221 [==============================] - 121s 29ms/step - loss: 0.0539 - mean_iou: 0.7682 - val_loss: 0.0487 - val_mean_iou: 0.7684\n",
      "Epoch 44/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.0531 - mean_iou: 0.7686Epoch 00044: val_loss improved from 0.04869 to 0.04859, saving model to model_02.h5\n",
      "4221/4221 [==============================] - 121s 29ms/step - loss: 0.0531 - mean_iou: 0.7686 - val_loss: 0.0486 - val_mean_iou: 0.7688\n",
      "Epoch 45/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.0526 - mean_iou: 0.7690Epoch 00045: val_loss improved from 0.04859 to 0.04808, saving model to model_02.h5\n",
      "4221/4221 [==============================] - 120s 28ms/step - loss: 0.0526 - mean_iou: 0.7690 - val_loss: 0.0481 - val_mean_iou: 0.7692\n",
      "Epoch 46/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.0527 - mean_iou: 0.7694Epoch 00046: val_loss improved from 0.04808 to 0.04780, saving model to model_02.h5\n",
      "4221/4221 [==============================] - 121s 29ms/step - loss: 0.0528 - mean_iou: 0.7694 - val_loss: 0.0478 - val_mean_iou: 0.7696\n",
      "Epoch 47/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.0528 - mean_iou: 0.7697Epoch 00047: val_loss did not improve\n",
      "4221/4221 [==============================] - 121s 29ms/step - loss: 0.0528 - mean_iou: 0.7697 - val_loss: 0.0499 - val_mean_iou: 0.7699\n",
      "Epoch 48/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.0536 - mean_iou: 0.7700Epoch 00048: val_loss improved from 0.04780 to 0.04770, saving model to model_02.h5\n",
      "4221/4221 [==============================] - 121s 29ms/step - loss: 0.0535 - mean_iou: 0.7700 - val_loss: 0.0477 - val_mean_iou: 0.7702\n",
      "Epoch 49/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.0519 - mean_iou: 0.7704Epoch 00049: val_loss improved from 0.04770 to 0.04751, saving model to model_02.h5\n",
      "4221/4221 [==============================] - 121s 29ms/step - loss: 0.0518 - mean_iou: 0.7704 - val_loss: 0.0475 - val_mean_iou: 0.7705\n",
      "Epoch 50/50\n",
      "4200/4221 [============================>.] - ETA: 0s - loss: 0.0524 - mean_iou: 0.7707Epoch 00050: val_loss improved from 0.04751 to 0.04696, saving model to model_02.h5\n",
      "4221/4221 [==============================] - 121s 29ms/step - loss: 0.0523 - mean_iou: 0.7707 - val_loss: 0.0470 - val_mean_iou: 0.7709\n"
     ]
    }
   ],
   "source": [
    "earlystopper = EarlyStopping(patience=5, verbose=1)\n",
    "checkpointer = ModelCheckpoint('model_02.h5', verbose=1, save_best_only=True)\n",
    "results = model.fit(X_train, Y_train, validation_split=0.1, batch_size=50, epochs=50, \n",
    "                    callbacks=[earlystopper, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
